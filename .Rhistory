sum(flag$orange)
sum(flags$orange)
flag_colors <- flag[, 11:17]
flag_colors <- flags[, 11:17]
head(flag_colors)
lapply(flag_colors, sum)
sapply(flag_color, sum)
sapply(flag_colors, sum)
sapply(flag_colors, mean)
flag_shapes <- flags[, 19:23]
lapply(flag_shapes, range)
shape_mat <- sapply(flag_shapes, range)
shape_mat
class(shape_mat)
unique(c(3,4,5,5,5,6,6))
unique_vals <- lapply(flags, unique)
unique_vals
length(unique_vals)
sapply(unique_vals, length)
sapply(flags, unique)
lapply(unique_vals, function(elem) elem[2])
sapply(flags, unique)
apply(flags, unique, numeric(1))
vapply(flags, unique, numeric(1))
ok()
sapply(flags, class)
sapply(flags, class, character(1))
vapply(flags, class, character(1))
?tapply
table(flags$landmass)
table(flags$animate)
tapply(flags$animate, flags$landmass, mean)
tapply(flags$population, flags$red, summary)
tapply(flags$population, flags$landmass, summary)
install_from_swirl("Data Analysis")
install_from_swirl("Mathematical Biostatistics Boot Camp")
install_from_swirl("Open Intro")
install_from_swirl("Getting and Cleaning Data")
install_from_swirl("Regression Models")
install_from_swirl("Statistical Inference")
swirl()
5
swirl
swirl()
ls()
class(plants)
dim(plants)
nrow(plants)
ncol(plants)
object.size(plants)
names(plants)
head(plants)
head(plants,10)
tail(plants,15)
summary(plants)
table(plants$Active_Growth_Period)
str(plants)
y<-100
cars$type
sqrt(y)
z<-sqrt(y)
?sqrt
cars
10
range(cars$price)
nxt()
sum(car$price)
sum(cars$price)
sum(cars$price)/nrow(cars)
mean(cars$price)
mpg.midsize
sort(mpg.midsize)
mpg.sorted <- sort(mpg.midsize)
19
median(mpg.midsize)
summary(cars$mpgCity)
25
1
9
19
nxt()
20
nxt()
sd(mpg.midsize)
sd(mpg.midsize)^2
25
quit
quit()
swirl()
library(swirl)
swirl()
mtcars
allMPG<-mtcars$mpg
allMPG
mean(allMPG)
sampMeanMPG <- mean(allMPG)
sampVarMPG <- var(allMPG)
n <- length(all_MPG)
n <- length(allMPG)
tStat <- (sampMeanMPG - 12.0) / sqrt(sampVarMPG/n)
myDF = n-1
tstat
tStat
myDF
pVal1 <- pt(tStat, df = myDF, lower.tail = FALSE)
pVal <- pVal1*2
pVal
t.test(allMPG, mu=12, alternative = "two.sided")
am
mtcars$am
auto <- mtcars[mtcars$am==0, ]
man <- mtcars[mtcars$am==1, ]
autoMPG <- auto[, MPG]
autoMPG <- auto[, 'MPG']
autoMPG <- auto[, 'mpg']
manMPG <- man[, 1]
sampMeanAutoMPG <- mean(autoMPG)
sampMeanManMPG <- mean(manMPG)
diffSampMean <- sampMeanManMPG - sampMeanAutoMPG
diffPopMean <- 0
sampVarAutoMPG <- var(autoMPG)
sampVarManMPG <- var(manMPG)
nAuto <- length(autoMPG)
nMan <- length(manMPG)
numer <- sampMeanAuto - sampMeanMan - diffSamMean
numer <- sampMeanAutoMPG - sampMeanManMPG - diffSamMean
numer <- sampMeanAutoMPG - sampMeanManMPG - diffSampMean
numer <- diffSampMean - diffPopMean
denom = sqrt(var(diffSampMean)/n)
denom <- sqrt(sampVarManMPG/nMan + sampVarAutoMPG/nAuto)
tStat <- numer/denom
myDF <- (sampVarManMPG/nMan + sampVarAutoMPG/nAuto)^2 / ((sampVarManMPG/nMan)^2/(nMan - 1) + (sampVarAutoMPG/nAuto)^2/(nAuto - 1))
tstat
tStat
myDF
pVal1 <- pt(tStat, myDF, lower.tail=FALSE)
pVal <- pVal1*2
pVal
t.test(diffSampMean, mu=0, alternative = "two.sided")
s
info()
t.test(AutoMPG, ManMPG, mu=0, alternative = "two.sided")
t.test(autoMPG, manMPG, mu=0, alternative = "two.sided")
info()
bye()
swirl
swirl()
sigma <- 10
delta <- 5
zAlpha <- qnorm(0.95)
zBeta <- qnorm(0.2)
(sigma / delta)^2 * (zAlpha - zBeta)^2
effectSize <- pwr.norm.test(delta, sigma)
effectSize <- delta/ sigma
pwr.norm.test(d=effectSize, sig.level=0.05, power=0.80, alternative="greater")
pwr.t.test(d=effectSize, sig.level=0.05, power=0.80, type="one.sample", alternative="greater")
data(mpg)
library(cars)
library('cars')
library('car')
data(mpg)
str(car)
library("swirl")
swirl()
str(galton)
plot(child ~ parent, galton)
plot(jitter(child,4) ~ parent, galton)
regrline <- lm(child ~ parent, galton)
abline(regrline, lwd = 3, col = 'red')
summary(regrline)
fit <- lm(child ~ parent, galton)
summary(fit)
mean(fit$residuals)
cov(fit$residuals, galton$parent)
ols.ic <- fit$coef[1]
ols.slope <- fit$coef[2]
rhs-lhs
lhs-rhs
all.equal(lhs,rhs)
varChild <- var(child)
varChild <- var(galton$child)
varRes <- var(galton$residuals)
varRes <- var(fit$residuals)
varEst(ols.slope,ols.ic)
varEst <- est(ols.slope,ols.ic)
varEst <- var(est(ols.slope,ols.ic))
all.equal(varChild, varRes+varEst)
efit <- lm(accel ~ mag + dist, attenu)
mean(efit$residuals)
cov(efit$residuals, attenu$mag)
cov(efit$residuals, attenu$dist)
library("swirl")
swirl()
cor(gpa_nor, gch_nor)
l_nor <- lm(gch_nor ~ gpa_nor)
library(ggplot2)
str(movies)
library(ggplot2)
str(movies)
ggplot(data = subset(movies, votes > 1000), aes(x = rating, y=votes)) + geom_point()
m + scale_y_continuous(name = "number of votes")
m <- ggplot(data = subset(movies, votes > 1000), aes(x = rating, y=votes)) + geom_point()
# Control of the x and y axes for continuous variables
# name, breaks, labels, limits, na.value, trans.
m + scale_y_continuous(name = "number of votes")
# name, breaks, labels, limits, na.value, trans.
m + scale_y_continuous(name = "number of votes (in 1000)",
labels = c(0,5,10,15))
m + scale_y_continuous(name = "number of votes", limits = c(50000, 1e+05))
m + xlab("movie rating") + ylab("number of votes")
+ ggtitle("Number of votes by movie rating")
# Alternatives for setting axis names
m + xlab("movie rating") + ylab("number of votes") +
ggtitle("Number of votes by movie rating")
m + labs(x = "movie rating", y = "number of votes", title = "Number of votes by movie rating")
d <- ggplot(data = diamonds, aes(x = cut)) + geom_bar()
d
d + scale_x_discrete(labels = c("F", "G", "VG", "P", "I"))
dsamp <- diamonds[sample(nrow(diamonds), 1000), ]
dd <- ggplot(data = dsamp, aes(x=carat, y=price, color = clarity)) +
geom_point())
dd <- ggplot(data = dsamp, aes(x=carat, y=price, color = clarity) +
geom_point()
)
dd <- ggplot(data = dsamp, aes(x=carat, y=price, color = clarity)) + geom_point()
dd
dd + scale_color_hue(l = 20, c = 200)
e <- ggplot(data = dsamp, aes(x=x, y=y, color=price)) + geom_point()
e
dd
dd + theme(legend.position = "bottom")
dd + theme(axis.title.x = element_text(size = 20), axis.title.y = element_text(size=20))
dd + theme(axis.title.x = element_text(size = 20), axis.title.y = element_text(size=20), axis.text = element_text(size = 16))
dd + theme_bw()
dd + annotate("text", x=2,y=4000, label = "p = 1")
dd + annotate("text", x=2,y=4000, label = "p = 2.3 %*% 10^{-3}", parse = T)
dd + annotate("text", x=2,y=4000, label = "p == 2.3 %*% 10^{-3}", parse = T)
??annotate
ggsave(filename = "dd.pdf", plot = dd, width = 6, height = 7)
install.packages("knitr")
install.packages("slidify")
install.packages(c("BH", "digest", "dplyr", "foreign", "httr", "jsonlite", "lazyeval", "manipulate", "mgcv", "RColorBrewer", "RCurl", "stringi", "swirl"))
install.packages("xtable")
library(Lahman)
install.packages("Lahman")
setwd("G:/Data Set for R/R programming")
library(dplyr)
library(hflights)
str(hflights)
hflights_df <- tbl_df(hflights)
class(hflights)
class(hflights_df)
f_df <- filter(hflights_df, Month==1, UniqueCarrier == "AA")
f_df
arrange(hflights_df, Month, DayofMonth, desc(AirTime))
select(hflights_df, Year:DayOfWeek, TailNum, ActualElapsedTime)
mutate(hflights_df, gain = ArrDelay - DepDelay, gain_per_hour = gain/(AirTime/60))
summarize(hflights_df, delay = mean(ArrDelay, na.rm = T))
library(plyr)
delay1 <- ddply(hflights, .(TailNum), function(df) {
data.frame(count = nrow(df), dist = mean(df$Distance, na.rm = T),
delay = mean(df$ArrDelay, na.rm = T))
})
str(delay1)
head(delay1)
planes <- group_by(hflights_df, TailNum)
delay2 <- summarize(planes, count = n(), dist = mean(Distance, na.rm = T),
delay = mean(ArrDelay, na.rm = T))
sessionInfo()
library(dplyr)
sessionInfo()
planes <- group_by(hflights_df, TailNum)
delay2 <- summarize(planes, count = n(), dist = mean(Distance, na.rm = T),
delay = mean(ArrDelay, na.rm = T))
planes <- group_by(hflights_df, TailNum)
delay2 <- summarize(planes, count = n(), dist = mean(Distance, na.rm = T), delay = mean(ArrDelay, na.rm = T))
delay2 <- summarize(planes, count = n (), dist = mean(Distance, na.rm = T), delay = mean(ArrDelay, na.rm = T))
delay2 <- summarise(planes, count = n (), dist = mean(Distance, na.rm = T), delay = mean(ArrDelay, na.rm = T))
delay2 <- summarise(planes, count = n(), dist = mean(Distance, na.rm = T), delay = mean(ArrDelay, na.rm = T))
delay2 <- summarise(planes,  dist = mean(Distance, na.rm = T), delay = mean(ArrDelay, na.rm = T))
conflicts()
library(dplyr)
planes <- group_by(hflights_df, TailNum)
delay2 <- summarise(planes, count = n(), dist = mean(Distance, na.rm = T), delay = mean(ArrDelay, na.rm = T))
# Using dplyr to group, manipulate and summarize data
setwd("G:/Data Set for R/R programming")
library(plyr)
library(dplyr)
library(hflights)
str(hflights)
# converting hflights to dbl_df object:
hflights_df <- tbl_df(hflights)
class(hflights_df)
## basic manipulations
# filter: filter the specific rows
# get the January flights for AA
f_df <- filter(hflights_df, Month==1, UniqueCarrier == "AA")
f_df
# for "or" you need to add |
# filter(hflights_df, UniqueCarrier=="UA" | UniqueCarrier == "AA")
# arrange: reorders the data based on specified columns
arrange(hflights_df, Month, DayofMonth, desc(AirTime))
# select: selection specific columns
select(hflights_df, Year:DayOfWeek, TailNum, ActualElapsedTime)
# mutate: adds new columns: similar to transform?
mutate(hflights_df, gain = ArrDelay - DepDelay, gain_per_hour = gain/(AirTime/60))
# summarise: produces a summary statistic
summarise(hflights_df, delay = mean(ArrDelay, na.rm = T))
## Group
# Compute mean arrival delay by plane, along with other useful data.
# use ddply and dplyr can do this
delay1 <- ddply(hflights, .(TailNum), function(df) {
data.frame(count = nrow(df), dist = mean(df$Distance, na.rm = T),
delay = mean(df$ArrDelay, na.rm = T))
})
# now use dplyr: 1. group; 2. summarize
planes <- group_by(hflights_df, TailNum)
delay2 <- summarise(planes, count = n(), dist = mean(Distance, na.rm = T), delay = mean(ArrDelay, na.rm = T))
#  presume you have dplyr and plyr loaded in the same session. dplyr is not plyr.
# ddply is not a function in the dplyr package. (Your title appears to suggest you may have both loaded)
# Both dplyr and plyr have the functions summarise/summarize.
# Look at the results of conflicts() to see masked objects.
conflicts()
library(dplyr)
library(hflights)
hflights_df <- tbl_df(hflights)
class(hflights_df)
planes <- group_by(hflights_df, TailNum)
delay2 <- summarise(planes, count = n(), dist = mean(Distance, na.rm = T), delay = mean(ArrDelay, na.rm = T))
delay2 <- summarize(planes, count = n(), dist = mean(Distance, na.rm = T), delay = mean(ArrDelay, na.rm = T))
# Using dplyr to group, manipulate and summarize data
setwd("G:/Data Set for R/R programming")
library(plyr)
library(dplyr)
library(hflights)
str(hflights)
# converting hflights to dbl_df object:
hflights_df <- tbl_df(hflights)
class(hflights_df)
## basic manipulations
# filter: filter the specific rows
# get the January flights for AA
f_df <- filter(hflights_df, Month==1, UniqueCarrier == "AA")
f_df
# for "or" you need to add |
# filter(hflights_df, UniqueCarrier=="UA" | UniqueCarrier == "AA")
# arrange: reorders the data based on specified columns
arrange(hflights_df, Month, DayofMonth, desc(AirTime))
# select: selection specific columns
select(hflights_df, Year:DayOfWeek, TailNum, ActualElapsedTime)
# mutate: adds new columns: similar to transform?
mutate(hflights_df, gain = ArrDelay - DepDelay, gain_per_hour = gain/(AirTime/60))
# summarise: produces a summary statistic
summarise(hflights_df, delay = mean(ArrDelay, na.rm = T))
## Group
# Compute mean arrival delay by plane, along with other useful data.
# use ddply and dplyr can do this
delay1 <- ddply(hflights, .(TailNum), function(df) {
data.frame(count = nrow(df), dist = mean(df$Distance, na.rm = T),
delay = mean(df$ArrDelay, na.rm = T))
})
# now use dplyr: 1. group; 2. summarize
planes <- group_by(hflights_df, TailNum)
class(planes)
delay2 <- summarise(planes, count = n(), dist = mean(Distance, na.rm = T), delay = mean(ArrDelay, na.rm = T))
delay2 <- summarise(planes, dist = mean(Distance, na.rm = T), delay = mean(ArrDelay, na.rm = T))
delay2
planes
destinations <- group_by(hflights_df, Dest)
summarise(destinations, planes = n_distinct(TailNum), flights = n())
summarise(destinations, planes = n_distinct(TailNum))
my_db <- src_sqlite("my_db.sqlite3", create = T)
setwd("C:/Users/Odin/Documents/GitHub/RepData_PeerAssessment1")
act_data <- read.csv("activity.csv", header = TRUE)
head(act_data)
fix(act_data)
str(act_data)
library(plyr)
library(ggplot2)
total_step_perday = ddply(act_data, .(date), function(df) sum(df$step, na.rm = TRUE))
ggplot(act_data, aes(x = act_data$date, y = act_data$step)) + geom_bar(stat = "identity")
str(total_step_perday)
ggplot(act_data, aes(x = total_step_perday$date, y = total_step_perday$V1)) + geom_bar(stat = "identity")
max(total_step_perday$V1)
max(act_data$step)
mean_step_perday = ddply(act_data, .(date), function(df) mean(df$step, na.rm = TRUE))
med_step_perday = ddply(act_data, .(date), function(df) median(df$step, na.rm = TRUE))
mean_step_perday
fix(act_data)
str(mean_step_perday)
ggplot(mean_step_perday, aes(x = date, y = V1)) + geom_bar(stat = "identity")
ggplot(med_step_perday, aes(x = date, y = V1)) + geom_bar(stat = "identity")
str(med_step_perday)
median(c(5,2,1))
med_step_perday = ddply(act_data, .(date), function(df) median(df$step, na.rm = TRUE))
median(c(5,2,1))
str(med_step_perday)
mean_step_perday = ddply(act_data, .(date), function(df) mean = mean(df$step, na.rm = TRUE))
str(mean_step_perday)
med_step_perday = ddply(act_data, .(date), function(df) median = median(df$step, na.rm = TRUE))
str(med_step_perday)
fix(act_data)
fix(act_data)
str(act_data
)
step_vs_interval = ddply(act_data, .(interval), function(df) mean = mean(df$step, na.rm = TRUE))
str(step_vs_interval)
names(step_vs_interval)[2] = "mean_steps";
str(step_vs_interval)
ggplot(act_data, aes(x = interval, y = mean_steps)) + geom_bar(stat = "identity")
ggplot(step_vs_interval, aes(x = interval, y = mean_steps)) + geom_bar(stat = "identity")
which.max(step_vs_interval$mean_steps)
?which.max
which.max(c(3,5,1))
which.max(c(3,5,1,5))
which.max(c(3,5,1,5,9))
step_vs_interval[104,:]
step_vs_interval[104,]
max_interval <- ste_vs_interval[max_index,1]
max_index <- which.max(step_vs_interval$mean_steps)
max_index
max_interval <- step_vs_interval[max_index,1]
max_interval
sum(is.na(act_data[,1]))
sum(is.na(act_data[,2]))
sum(is.na(act_data[,3]))
sum(is.na(act_data[,4]))
sum(is.na(act_data))
miss_num <- sum(is.na(act_data[,1]))
echo miss_num
miss_num
??which.na
a <- which(is.na(act_data[,1])
)
str(a)
miss_row_index <- which(is.na(act_data[,1])
)
class(miss_row_index)
type(miss_row_index)
str(miss_row_index)
miss_row_index[1]
fix(act_data)
str(step_vs_interval)
288*5
step_vs_interval
str(act_data)
str(step_vs_interval)
step_vs_interval$interval==5
step_vs_interval[step_vs_interval==5]
step_vs_interval[step_vs_interval==5][mean_steps]
step_vs_interval$mean_steps[step_vs_interval==5]
step_vs_interval$mean_steps[step_vs_interval==6]
step_vs_interval$mean_steps[step_vs_interval==10]
step_vs_interval$mean_steps
step_vs_interval$mean_steps[283]
str(interval_value)
str(step_vs_interval)
act_data[miss_row_index[i],1] <- step_vs_interval$mean_steps[step_vs_interval$interval == interval_value]
miss_row_index <- which(is.na(act_data[,1]))
for (i in 1:miss_num)
{
interval_value <- act_data[miss_row_index[i],3]
act_data[miss_row_index[i],1] <- step_vs_interval$mean_steps[step_vs_interval$interval == interval_value]
}
fix(interval)
fix(act_data)
setwd("C:/Users/Odin/Documents/GitHub/RepData_PeerAssessment1")
## Loading and preprocessing the data
# read the data from csv file
act_data <- read.csv("activity.csv", header = TRUE)
library(plyr)
library(ggplot2)
## What is mean total number of steps taken per day?
# ignore the missing values
# histogram
ggplot(act_data, aes(x = act_data$date, y = act_data$step)) + geom_bar(stat = "identity")
#total_step_perday = ddply(act_data, .(date), function(df) sum(df$step, na.rm = TRUE))
#ggplot(act_data, aes(x = total_step_perday$date, y = total_step_perday$V1)) + geom_bar(stat = "identity")
# compute mean and meadian of steps per day
mean_step_perday = ddply(act_data, .(date), function(df) mean = mean(df$step, na.rm = TRUE))
med_step_perday = ddply(act_data, .(date), function(df) median = median(df$step, na.rm = TRUE))
ggplot(mean_step_perday, aes(x = date, y = V1)) + geom_bar(stat = "identity")
ggplot(med_step_perday, aes(x = date, y = V1)) + geom_bar(stat = "identity")
## What is the average daily activity pattern
# Make a time series plot (i.e. type = "l") of the 5-minute interval (x-axis) and
# the average number of steps taken, averaged across all days (y-axis)
step_vs_interval = ddply(act_data, .(interval), function(df) mean = mean(df$step, na.rm = TRUE))
names(step_vs_interval)[2] = "mean_steps";
ggplot(step_vs_interval, aes(x = interval, y = mean_steps)) + geom_bar(stat = "identity")
max_index <- which.max(step_vs_interval$mean_steps)
max_index
max_interval <- step_vs_interval[max_index,1]
max_interval
# the maximum mean steps is 206.1698 at the 104th interval (835)
## Imputing missing values; missing values only exist in "steps"
miss_num <- sum(is.na(act_data[,1]))
miss_num # 2304
act_data_2 <- act_data
miss_row_index <- which(is.na(act_data_2[,1]))
for (i in 1:miss_num)
{
interval_value <- act_data_2[miss_row_index[i],3]
act_data_2[miss_row_index[i],1] <- step_vs_interval$mean_steps[step_vs_interval$interval == interval_value]
}
ggplot(act_data_2, aes(x = date, y = step)) + geom_bar(stat = "identity")
ggplot(act_data_2, aes(x = act_data_2$date, y = act_data_2$step)) + geom_bar(stat = "identity")
str(act_data_2)
mean(act_data_2$steps)
mean(act_data$steps)
mean(act_data$steps, na.rm = TRUE)
median(act_data_2$steps)
median(act_data$steps, na.rm = TRUE)
